trainDataSet <- createDataPartition(y=trainData$classe, p=0.70, list=FALSE)
library(caret)
library(knitr)
library(ggplot2)
library(dplyr)
library(randomForest)
trainData <- read.csv(file = "pml-training.csv", na.strings=c("", "NA", "NULL"))
testData <- read.csv(file = "pml-testing.csv", na.strings=c("", "NA", "NULL"))
str(trainData, list.len=15)
table(trainData$classe)
prop.table(table(trainData$user_name, trainData$classe), 1)
prop.table(table(trainData$classe))
is_data  <- apply(!is.na(trainData), 2, sum) > 19622  # which is the number of observations
trainData <- trainData[, is_data]
testData  <- testData[, is_data]
set.seed(109354)
trainDataSet <- createDataPartition(y=trainData$classe, p=0.70, list=FALSE)
trainDataSet <- createDataPartition(trainData$classe,times = 1, p=0.70, list=FALSE)
is_data  <- apply(!is.na(trainData), 2, sum) > 19622  # which is the number of observations
trainData <- trainData[, is_data]
dim(trainDataSet)
dim(trainData)
is_data  <- apply(!is.na(trainData), 2, sum) > 19621  # which is the number of observations
trainData <- trainData[, is_data]
testData  <- testData[, is_data]
```
```{r}
set.seed(109354)
trainDataSet <- createDataPartition(trainData$classe,times = 1, p=0.70, list=FALSE)
dim(trainData)
summary(trainData)
trainData <- read.csv(file = "pml-training.csv", na.strings=c("", "NA", "NULL"))
testData <- read.csv(file = "pml-testing.csv", na.strings=c("", "NA", "NULL"))
```
str(trainData, list.len=15)
table(trainData$classe)
prop.table(table(trainData$user_name, trainData$classe), 1)
prop.table(table(trainData$classe))
is_data  <- apply(!is.na(trainData), 2, sum) > 19621  # which is the number of observations
trainData1 <- trainData[, is_data]
testData1  <- testData[, is_data]
set.seed(109354)
trainDataSet <- createDataPartition(trainData1$classe,times = 1, p=0.70, list=FALSE)
trainDataSet  <- training[trainDataSet,]
trainDataSet <- createDataPartition(trainData1$classe,times = 1, p=0.70, list=FALSE)
trainDataSet  <- trainData1[trainDataSet,]
testDataSet  <- trainData1[-trainDataSet,]
dim(trainDataSet)
str(trainData, list.len=15)
table(trainData$classe)
prop.table(table(trainData$user_name, trainData$classe), 1)
prop.table(table(trainData$classe))
```
```{r}
is_data  <- apply(!is.na(trainData), 2, sum) > 19621  # which is the number of observations
trainData1 <- trainData[, is_data]
testData1  <- testData[, is_data]
```
```{r}
set.seed(109354)
trainDataSet <- createDataPartition(trainData1$classe,times = 1, p=0.70, list=FALSE)
trainDataSet  <- trainData1[trainDataSet,]
testDataSet  <- trainData1[-trainDataSet,]
trainData <- read.csv(file = "pml-training.csv", na.strings=c("", "NA", "NULL"))
testData <- read.csv(file = "pml-testing.csv", na.strings=c("", "NA", "NULL"))
str(trainData, list.len=15)
table(trainData$classe)
prop.table(table(trainData$user_name, trainData$classe), 1)
prop.table(table(trainData$classe))
NA_Count = sapply(1:dim(trainData)[2],function(x)sum(is.na(trainData[,x])))
NA_list = which(NA_Count>0)
colnames(trainData[,c(1:7)])
trainData = trainData[,-NA_list]
trainData = trainData[,-c(1:7)]
trainData$classe = factor(trainData$classe)
testData = testData[,-NA_list]
testData = testData[,-c(1:7)]
```
```{r}
set.seed(109354)
trainDataSet <- createDataPartition(trainData$classe, times = 1, p=0.70, list=FALSE)
trainDataSet  <- trainData[trainDataSet,]
testDataSet  <- trainData[-trainDataSet,]
trainDataSet
summary(trainDataSet)
NA_Count
NA_list
colnames
trainData = trainData[,-NA_list]
summary(trainData)
dim(trainData)
dim(testData)
install.packages("doParallel")
setwd("D:/Users/Tracy/Documents/R/Machine Learning/Project")
pml_write_files = function(x){
n = length(x)
path <- "answers"
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=file.path(path, filename),quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(hat)
DTestCS <- predict(preProc, DTest[, predCandidates, with=FALSE])
library(data.table)
setInternet2(TRUE)
url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
D <- fread(url)
url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
DTest <- fread(url)
isAnyMissing <- sapply(DTest, function (x) any(is.na(x) | x == ""))
isPredictor <- !isAnyMissing & grepl("belt|[^(fore)]arm|dumbbell|forearm", names(isAnyMissing))
predCandidates <- names(isAnyMissing)[isPredictor]
predCandidates
varToInclude <- c("classe", predCandidates)
D <- D[, varToInclude, with=FALSE]
dim(D)
names(D)
D <- D[, classe := factor(D[, classe])]
D[, .N, classe]
library(caret)
seed <- as.numeric(as.Date("2014-10-26"))
set.seed(seed)
inTrain <- createDataPartition(D$classe, p=0.6)
DTrain <- D[inTrain[[1]]]
DProbe <- D[-inTrain[[1]]]
X <- DTrain[, predCandidates, with=FALSE]
preProc <- preProcess(X)
preProc
XCS <- predict(preProc, X)
DTrainCS <- data.table(data.frame(classe = DTrain[, classe], XCS))
X <- DProbe[, predCandidates, with=FALSE]
XCS <- predict(preProc, X)
DProbeCS <- data.table(data.frame(classe = DProbe[, classe], XCS))
nzv <- nearZeroVar(DTrainCS, saveMetrics=TRUE)
if (any(nzv$nzv)) nzv else message("No variables with near zero variance")
histGroup <- function (data, regex) {
col <- grep(regex, names(data))
col <- c(col, which(names(data) == "classe"))
library(reshape2)
n <- nrow(data)
DMelted <- melt(data[, col, with=FALSE][, rownum := seq(1, n)], id.vars=c("rownum", "classe"))
library(ggplot2)
ggplot(DMelted, aes(x=classe, y=value)) +
geom_violin(aes(color=classe, fill=classe), alpha=1/2) +
#     geom_jitter(aes(color=classe, fill=classe), alpha=1/10) +
#     geom_smooth(aes(group=1), method="gam", color="black", alpha=1/2, size=2) +
facet_wrap(~ variable, scale="free_y") +
scale_color_brewer(palette="Spectral") +
scale_fill_brewer(palette="Spectral") +
labs(x="", y="") +
theme(legend.position="none")
}
histGroup(DTrainCS, "belt")
histGroup(DTrainCS, "[^(fore)]arm")
histGroup(DTrainCS, "dumbbell")
histGroup(DTrainCS, "forearm")
library(parallel)
library(doParallel)
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
ctrl <- trainControl(classProbs=TRUE,
savePredictions=TRUE,
allowParallel=TRUE)
method <- "rf"
system.time(trainingModel <- train(classe ~ ., data=DTrainCS, method=method))
stopCluster(cl)
trainingModel
hat <- predict(trainingModel, DTrainCS)
confusionMatrix(hat, DTrain[, classe])
hat <- predict(trainingModel, DProbeCS)
confusionMatrix(hat, DProbeCS[, classe])
varImp(trainingModel)
trainingModel$finalModel
setwd("D:/Users/Tracy/Documents/R/Machine Learning/Project")
save(trainingModel, file="trainingModel.RData")
load(file="trainingModel.RData", verbose=TRUE)
DTestCS <- predict(preProc, DTest[, predCandidates, with=FALSE])
hat <- predict(trainingModel, DTestCS)
DTest <- cbind(hat , DTest)
subset(DTest, select=names(DTest)[grep("belt|[^(fore)]arm|dumbbell|forearm", names(DTest), invert=TRUE)])
setwd("D:/Users/Tracy/Documents/R/Machine Learning/Project")
pml_write_files = function(x){
n = length(x)
path <- "answers"
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=file.path(path, filename),quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(hat)
pml_write_files = function(x){
n = length(x)
path <- "answers"
path <- "D:/Users/Tracy/Documents/R/Machine Learning/Project/answers"
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=file.path(path, filename),quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(hat)
pml_write_files = function(x){
n = length(x)
path <- "D:\Users\Tracy\Documents\R\Machine Learning\answers"
path <- "D:/Users/Tracy/Documents/R/Machine Learning/answers"
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=file.path(path, filename),quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(hat)
NA_Count = sapply(1:dim(trainData)[2],function(x)sum(is.na(trainData[,x])))
NA_Count
NA_list = which(NA_Count>0)
NA_list
trainData <- read.csv(file = "pml-training.csv", na.strings=c("", "NA", "NULL"))
testData <- read.csv(file = "pml-testing.csv", na.strings=c("", "NA", "NULL"))
str(trainData, list.len=15)
table(trainData$classe)
prop.table(table(trainData$user_name, trainData$classe), 1)
prop.table(table(trainData$classe))
NA_Count = sapply(1:dim(trainData)[2],function(x)sum(is.na(trainData[,x])))
NA_list = which(NA_Count>0)
colnames(trainData[,c(1:7)])
trainData = trainData[,-NA_list]
trainData = trainData[,-c(1:7)]
trainData$classe = factor(trainData$classe)
testData = testData[,-NA_list]
testData = testData[,-c(1:7)]
View(testSA)
View(trainData)
View(trainData)
set.seed(1255)
trainDataSet <- createDataPartition(trainData$classe, times = 1, p=0.70, list=FALSE)
trainDataSet  <- trainData[trainDataSet,]
testDataSet  <- trainData[-trainDataSet,]
testDataSet  <- trainData[-trainDataSet,]
trainDataSet <- createDataPartition(trainData$classe, times = 1, p=0.70, list=FALSE)
trainDataSet  <- trainData[trainDataSet,]
testDataSet  <- trainData[-trainDataSet,]
dim(trainDataSet)
dim(trainDataSet)
dim(testDataSet)
testData = testData[,-NA_list]
testData = testData[,-c(1:7)]
testData$classe = factor(testData$classe)
View(X)
set.seed(1255)
trainDataSet <- createDataPartition(trainData$classe, times = 1, p=0.70, list=FALSE)
trainDataSet  <- trainData[trainDataSet,]
testDataSet  <- trainData[-trainDataSet,]
NA_Count = sapply(1:dim(trainData)[2],function(x)sum(is.na(trainData[,x])))
NA_list = which(NA_Count>0)
colnames(trainData[,c(1:7)])
trainData = trainData[,-NA_list]
trainData = trainData[,-c(1:7)]
trainData$classe = factor(trainData$classe)
testData = testData[,-NA_list]
testData <- read.csv(file = "pml-testing.csv", na.strings=c("", "NA", "NULL"))
NA_Count = sapply(1:dim(trainData)[2],function(x)sum(is.na(trainData[,x])))
NA_list = which(NA_Count>0)
colnames(trainData[,c(1:7)])
trainData = trainData[,-NA_list]
trainData = trainData[,-c(1:7)]
trainData$classe = factor(trainData$classe)
trainData <- read.csv(file = "pml-training.csv", na.strings=c("", "NA", "NULL"))
testData <- read.csv(file = "pml-testing.csv", na.strings=c("", "NA", "NULL"))
str(trainData, list.len=15)
table(trainData$classe)
prop.table(table(trainData$user_name, trainData$classe), 1)
prop.table(table(trainData$classe))
str(testData, list.len=15)
table(testData$classe)
prop.table(table(testData$user_name, testData$classe), 1)
prop.table(table(testData$classe))
trainData <- read.csv(file = 'data_train.csv',
na.strings = c('NA','#DIV/0!',''))
setwd("D:/Users/Tracy/Documents/R/Machine Learning/Project")
library(caret)
library(knitr)
library(ggplot2)
library(dplyr)
library(randomForest)
trainData <- read.csv(file = 'data_train.csv',
na.strings = c('NA','#DIV/0!',''))
trainData <- read.csv(file = 'pml-training.csv',
na.strings = c('NA','#DIV/0!',''))
testData <- read.csv(file = 'pml-testing.csv',
na.strings = c('NA','#DIV/0!',''))
str(trainData, list.len=15)
str(testData, list.len=15)
for(i in c(8:ncol(trainData)-1)) {
trainData[,i] = as.numeric(as.character(trainData[,i]))
testData[,i] = as.numeric(as.character(testData[,i]))
}
feature_index <- colnames(trainData)
feature_index <- colnames(trainData[colSums(is.na(trainData)) == 0])
feature_index <- feature_index[-c(1:7)]
pml_train
set.seed(1255)
index_train <- createDataPartition(y=trainData$classe, p=0.80, list=FALSE)
trainDataSet <- trainData[index_train,feature_index]
evalDataSet <- trainData[-index_train,feature_index]
dim(trainDataSet); dim(evalDataSet)
modelRF <- train(classe ~ .,
data = trainDataSet,
method = 'rf',
trControl = trainControl(method = "cv",
number = 4,
allowParallel = TRUE,
verboseIter = TRUE))
modelRF <- train(classe ~ .,
data = trainDataSet,
method = 'rf',
trControl = trainControl(method = "cv",
number = 4,
allowParallel = TRUE,
verboseIter = TRUE))
modelRF <- train(classe ~ .,
data = trainDataSet,
method = 'rf', prox = TRUE)
setwd("D:/Users/Tracy/Documents/R/Machine Learning/Project")
library(caret)
library(knitr)
library(ggplot2)
library(dplyr)
library(randomForest)
trainData <- read.csv(file = 'pml-training.csv',
na.strings = c('NA','#DIV/0!',''))
testData <- read.csv(file = 'pml-testing.csv',
na.strings = c('NA','#DIV/0!',''))
str(trainData, list.len=15)
str(testData, list.len=15)
for(i in c(8:ncol(trainData)-1)) {
trainData[,i] = as.numeric(as.character(trainData[,i]))
testData[,i] = as.numeric(as.character(testData[,i]))
}
feature_index <- colnames(trainData)
feature_index <- colnames(trainData[colSums(is.na(trainData)) == 0])
feature_index <- feature_index[-c(1:7)]
set.seed(1255)
index_train <- createDataPartition(y=trainData$classe, p=0.80, list=FALSE)
trainDataSet <- trainData[index_train,feature_index]
evalDataSet <- trainData[-index_train,feature_index]
dim(trainDataSet); dim(evalDataSet)
```
modelRF <- train(classe ~ .,
data = trainDataSet,
method = 'rf',
trControl = trainControl(method = "cv",
number = 4,
allowParallel = TRUE,
verboseIter = TRUE))
install.packages(c("chron", "cluster", "dplyr", "gtools", "MASS", "Matrix", "plyr", "rversions", "scales", "survival", "XML"))
install.packages(c("chron", "cluster", "dplyr", "gtools", "MASS",
)
install.packages(c("chron", "cluster", "dplyr", "gtools"))
install.packages(c("chron", "cluster", "dplyr", "gtools"))
install.packages(c("chron", "cluster", "dplyr", "gtools"))
install.packages(c("chron", "cluster", "dplyr", "gtools"))
install.packages(c("chron", "cluster", "dplyr", "gtools"))
View(geocodes)
install.packages(c("MASS", "Matrix", "plyr", "rversions", "scales", "survival", "XML"))
setwd("D:/Users/Tracy/Documents/R/Machine Learning/Project")
library(caret)
library(knitr)
library(ggplot2)
library(dplyr)
library(randomForest)
trainData <- read.csv(file = 'pml-training.csv',
na.strings = c('NA','#DIV/0!',''))
testData <- read.csv(file = 'pml-testing.csv',
na.strings = c('NA','#DIV/0!',''))
str(trainData, list.len=15)
str(testData, list.len=15)
for(i in c(8:ncol(trainData)-1)) {
trainData[,i] = as.numeric(as.character(trainData[,i]))
testData[,i] = as.numeric(as.character(testData[,i]))
}
feature_index <- colnames(trainData)
feature_index <- colnames(trainData[colSums(is.na(trainData)) == 0])
feature_index <- feature_index[-c(1:7)]
set.seed(1255)
index_train <- createDataPartition(y=trainData$classe, p=0.80, list=FALSE)
trainDataSet <- trainData[index_train,feature_index]
evalDataSet <- trainData[-index_train,feature_index]
dim(trainDataSet); dim(evalDataSet)
modelRF <- train(classe ~ .,
data = trainDataSet,
method = 'rf',
trControl = trainControl(method = "cv",
number = 4,
allowParallel = TRUE,
verboseIter = TRUE))
modelRF <- train(classe ~ ., data = trainDataSet, method = 'rf', trControl = trainControl(method = "cv", number = 4, allowParallel = TRUE, verboseIter = TRUE))
predictRF <- predict(modelRF,evalDataSet)
confusionRF <- confusionMatrix(predictRF,evalDataSet$classe)
trainData <- read.csv(file = 'pml-training.csv',
na.strings = c('NA','#DIV/0!',''))
testData <- read.csv(file = 'pml-testing.csv',
na.strings = c('NA','#DIV/0!',''))
str(trainData, list.len=15)
str(testData, list.len=15)
for(i in c(8:ncol(trainData)-1)) {
trainData[,i] = as.numeric(as.character(trainData[,i]))
testData[,i] = as.numeric(as.character(testData[,i]))
}
pertinentDataIndex <- colnames(trainData)
pertinentDataIndex <- colnames(trainData[colSums(is.na(trainData)) == 0])
pertinentDataIndex <- pertinentDataIndex[-c(1:7)]
set.seed(1255)
index_train <- createDataPartition(y=trainData$classe, p=0.70, list=FALSE)
trainDataSet <- trainData[index_train,pertinentDataIndex]
evalDataSet <- trainData[-index_train,pertinentDataIndex]
dim(trainDataSet)
dim(evalDataSet)
ggplot(aes(x=classe), data=trainDataSet) +
geom_histogram(fill='dark orange') +
ggtitle('Histogram of Classe Frequency in Training Set') +
xlab('Classe of Excercise') +
ylab('Frequency in Training Data')
ggplot(trainDataSet, aes(x=classe, y=value)) +
geom_violin(aes(color=classe, fill=classe), alpha=1/2) +
#     geom_jitter(aes(color=classe, fill=classe), alpha=1/10) +
#     geom_smooth(aes(group=1), method="gam", color="black", alpha=1/2, size=2) +
facet_wrap(~ variable, scale="free_y") +
scale_color_brewer(palette="Spectral") +
scale_fill_brewer(palette="Spectral") +
labs(x="", y="") +
theme(legend.position="none")
}
ggplot(trainDataSet, aes(x=classe, y=value)) +
geom_violin(aes(color=classe, fill=classe), alpha=1/2) +
facet_wrap(~ variable, scale="free_y") +
scale_color_brewer(palette="Spectral") +
scale_fill_brewer(palette="Spectral") +
labs(x="", y="") +
theme(legend.position="none")
ggplot(data=trainDataSet) +
geom_tile(aes(x=Reference, y=Prediction, fill=Freq)) +
ggtitle('Prediction Accuracy for Classes in Cross-Validation (Random Forest Model)') +
xlab('Actual Classe') +
ylab('Predicted Classe from Model')
ggplot(data=trainDataSet) +
geom_tile(aes(x=Reference, y=Prediction, fill=Freq)) +
ggtitle('Prediction Accuracy for Classes in Cross-Validation (Random Forest Model)')
ggplot(aes(x=classe), data=trainDataSet) +
geom_histogram(fill='gray') +
ggtitle('Histogram of Classe Frequency in Training Set') +
xlab('Classe of Excercise') +
ylab('Frequency in Training Data')
modelRF <- train(classe ~ ., data = trainDataSet, method = 'rf',
trControl = trainControl(method = "cv", number = 4, allowParallel = TRUE, verboseIter = TRUE))
predictRF <- predict(modelRF,evalDataSet)
confusionRF <- confusionMatrix(predictRF,evalDataSet$classe)
ggplot(data=data.frame(confusionRF$table)) +
geom_tile(aes(x=Reference, y=Prediction, fill=Freq)) +
ggtitle('Prediction Accuracy for Classes in Cross-Validation (Random Forest Model)') +
xlab('Actual Classe') +
ylab('Predicted Classe from Model')
cm_rf
confusionRF
```
The accuracy of the model is  **`r confusionRF$overall['Accuracy']`** . The out of sample error is  **`r 1 - confusionRF$overall['Accuracy']`** . The out of sample error is calculated as **`r  1 - accuracy`**  for predictions made against the cross-validation set. Considering that the test set is a sample size of 20, an accuracy rate well above 99% is sufficient to expect that few or none of the test samples will be mis-classified.
##Display the final model
finalCol <- length(colnames(testData[]))
colnames(testData)[finalCol] <- 'classe'
quizRF <- predict(modelRF,testData[,pertinentDataIndex])
quizRF
answers = rep("A", 20)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=quizRF,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
finalCol <- length(colnames(testData[]))
colnames(testData)[finalCol] <- 'classe'
answers <- predict(modelRF,testData[,pertinentDataIndex])
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=quizRF,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
install.packages("ggplot2")
library(dplyr, quietly=TRUE)
setwd("D:/Users/Tracy/Documents/R/Machine Learning/Project/Machine-Learning-Project")
library(caret, quietly=TRUE)
library(knitr, quietly=TRUE)
library(ggplot2, quietly=TRUE)
library(dplyr, quietly=TRUE)
library(ggplot2, quietly = TRUE)
library(randomForest, quietly=TRUE)
```
install.packages("plyr")
install.packages("ggplot2")
install.packages("caret")
library(caret, quietly=TRUE)
R.Version()
